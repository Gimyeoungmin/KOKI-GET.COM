// package.json
{
  "name": "superintel-app",
  "version": "1.0.0",
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start"
  },
  "dependencies": {
    "next": "latest",
    "react": "latest",
    "react-dom": "latest",
    "openai": "^4.0.0",
    "axios": "^1.0.0"
  }
}

// next.config.js
/** @type {import('next').NextConfig} */
const nextConfig = {
  reactStrictMode: true,
};
module.exports = nextConfig;

// .env.local
OPENAI_API_KEY=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
CLAUDE_API_KEY=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

// pages/index.js
import { useState } from 'react';

export default function Home() {
  const [input, setInput] = useState("");
  const [output, setOutput] = useState("");
  const [loading, setLoading] = useState(false);

  const sendPrompt = async () => {
    setLoading(true);
    const res = await fetch('/api/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ prompt: input }),
    });
    const data = await res.json();
    setOutput(data.response);
    setLoading(false);
  };

  return (
    <main className="p-8">
      <h1 className="text-3xl mb-4">Superintel Chat</h1>
      <textarea
        rows={4}
        className="w-full p-2 border rounded"
        value={input}
        onChange={(e) => setInput(e.target.value)}
        placeholder="Enter your prompt..."
      />
      <button
        className="mt-2 px-4 py-2 rounded bg-blue-600 text-white"
        onClick={sendPrompt}
        disabled={loading}
      >
        {loading ? 'Thinking...' : 'Send'}
      </button>
      <pre className="mt-4 p-4 bg-gray-100 rounded">{output}</pre>
    </main>
  );
}

// pages/api/chat.js
import { queryOpenAI } from '../../utils/openai';
import { queryClaude } from '../../utils/claude';

export default async function handler(req, res) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }
  const { prompt } = req.body;
  try {
    const [gptRes, claudeRes] = await Promise.all([
      queryOpenAI(prompt),
      queryClaude(prompt),
    ]);
    const combined = `OpenAI says:\n${gptRes}\n\nClaude says:\n${claudeRes}`;
    res.status(200).json({ response: combined });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: 'API error' });
  }
}

// utils/openai.js
import OpenAI from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function queryOpenAI(prompt) {
  const completion = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: [{ role: 'user', content: prompt }],
  });
  return completion.choices[0].message.content;
}

// utils/claude.js
import axios from 'axios';

const CLAUDE_URL = 'https://api.anthropic.com/v1/complete';

export async function queryClaude(prompt) {
  const response = await axios.post(
    CLAUDE_URL,
    {
      model: 'claude-2',
      prompt,
      max_tokens_to_sample: 1000,
    },
    {
      headers: {
        'x-api-key': process.env.CLAUDE_API_KEY,
        'Content-Type': 'application/json',
      },
    }
  );
  return response.data.completion;
}

// README.md
# Superintel App

A Next.js application combining OpenAI GPT-4 and Anthropic Claude into a single ‚Äúsuperintelligence‚Äù chat interface.

## Features

- Query both GPT-4 and Claude concurrently.
- Simple UI with prompt input and combined response display.
- Easy deployment with Vercel.

## Setup

1. Clone this repository:
   ```bash
   git clone <repo-url>
   cd superintel-app
   ```
2. Install dependencies:
   ```bash
   npm install
   ```
3. Create `.env.local` in the root directory:
   ```
   OPENAI_API_KEY=sk-...
   CLAUDE_API_KEY=sk-...
   ```
4. Run development server:
   ```bash
   npm run dev
   ```
5. For production build:
   ```bash
   npm run build
   npm start
   ```

## Deployment to Vercel

1. Install Vercel CLI: `npm i -g vercel`
2. In project directory, run: `vercel`
3. Follow prompts and set environment variables.
4. Visit the provided deployment URL.

---

Now you have a live superintelligence chat! üéâ
